\chapter{研究现状}
\label{cha:china}
本章对跨语言对齐与知识库构建涉及到的相关技术进行了研究与探讨，主要对schema对齐、跨语言实体对齐跨语言属性对齐以及一些知名知识库的构建流程与技术上给出了详细的介绍，在这些研究的启发下，结合实际问题与切实数据情况，提出属性对齐方法与跨语言知识库的构建流程。

\section{本章引论}
自从Time Berner-Lee提出语义万维网的概念并规划出发展前景，语义网逐渐受到研究领域的关注，开始快速发展。通过语义万维网的直接目标：即让计算机理解语义文本，加强自动交流，可以预见语义网的建立要结合人工智能与Web技术。以自然语言处理、信息检索、机器学习为首的人工智能负责对纯文本进行分析、清理、语义理解、知识融合等工作，而Web技术则主导解析HTML文本，以及为知识关联与利用提供语义化环境等。从当前技术的发展趋势来看，作为人工智能与Web相结合的产物，语义网的出现，也是万维网发展的必然结果。

知识图谱是语义网发展过程中的产物。这一概念最初由谷歌提出，是谷歌对其建立的知识库产品的称呼，其作用为理解用户搜索内容，从更深、更广的角度提供一个全面的搜索结果。现在这一名称被广泛用来指代大规模知识库。知识图谱涵盖大量实体，同时以RDF三元组，即主语-谓语-宾语的形式存储着与实体与其他实体、概念、属性之间的关系。一般来说，一个实体属于一个或多个概念，还含有多个facts，表征该实体的特性。与精准度高的本体不同的是，知识图谱规模庞大，一般从多个数据源中精炼而成，具有一定的容错性，如何自动融合多源知识，如何提取正确关系，一直是知识图谱不可避免的阻碍，也是该领域广受关注的研究点。发布于开放链接(LOD)项目中的大规模开放数据集，都可称之为知识图谱。本章将对现今知识库现状进行讨论，并列举比较典型或相关的知识库，探讨其优缺点，xxx（详见\ref{sec:knowledgebase-research}）,并从实体的角度，介绍其目前常见问题与应用（详见\ref{sec:entity-research}）。

针对从海量数据分析中构建知识图谱这一问题，YAGO作者在文献\cite{suchanek2014knowledge} 中提及，其中一项有着重要意义的工作为获取关系事实。关系事实表征着实体的属性，以及实体与其他实体的关系，比如“清华大学-现任校长-邱勇”，即为一个关系事实。规模较小的领域本体，因实体类型限制在一定领域，其涉及的属性也屈指可数，一般可以通过人工直接定义\cite{boyce2007developing}或人工抽取\cite{王巍巍2016双语影视知识图谱的构建研究}来获得。然而以百科等大型数据集为来源的知识图谱，通常从页面信息框中提取关系事实与属性，数量在万级以上，杂质较多，准确度不能保证。基于此，对百科信息框属性的研究也数不胜数。\ref{sec:property-research} 中将会从跨语言属性对齐、属性模板、xxx方面来阐述近些年对百科信息框属性的研究，这些工作与知识库构建息息相关，对我们的属性相关任务有着很大的指导意义。

\section{百科信息框属性相关研究}
\label{sec:property-research}
在线百科的信息框融合了很多重要的、结构化信息。信息框是有一个实体的属性-属性值对罗列组成，这些信息对包含了该实体总结性信息。如果能充分利用这些信息，可以在xx方面有所突破。当前已有大量针对信息框与属性的研究，主要包括属性抽取\cite{}、相似属性查找、属性模板生成、信息框填充、跨语言属性对齐等等方向。

{\heiti 属性抽取}指从普通文本或结构化数据中抽取属性对工作，通常基于词法-句法规则匹配方法\cite{pacsca2007role,lee2013attribute}，或从网页table或list中通过<td>，<li>等标签获得\cite{crestan2010web}，并且通过不同的测量方法过滤掉错误的抽取对，如基于出现频率\cite{pacsca2007role}、人工规则\cite{lee2013attribute}等。本文针对维基百科的模板特点，给出基于Infobox、表格、与继承模板三种类型的抽取过程，将在\ref{sec:}中详细说明。

{\heiti 相似属性查找}的目标是将表示相同意义的属性找出并合并成一组。此工作可以转换成寻找相似字符串的问题，最简单的思想是利用字符串相似度匹配方法，常见的算法有

余弦相似度算法

Jaccard距离算法

编辑距离

其他的衡量方法依赖已有的知识资源（如WordNet）\cite{yang2005measuring}，或者语境分布\cite{pantel2009web}。

大部分寻找同义属性的工作都是基于英文的，中文相关工作较少。并且，由于中文方块字特征（如没有大小写区分、没有空格等），基于中文属性的工作则更加困难。文献\cite{liu2014extracting}以百度百科为数据源，结合文本相似度、语义相似度、上下文相似度，寻找中文相似属性。与本文的工作相似。

{\heiti 属性模板生成}通过

{\heiti 信息框填充}可以看作是信息抽取问题，从词条文本中抽取主语-关系-宾语三元组，为缺失属性抽取属性值。KYLIN\cite{wu2007autonomously}是第一个解决信息框缺失问题的系统，它使用自监督方法，在训练数据足够时效果不错。WikiCiKE\cite{wang2013transfer} 在跨语言数据集上，使用基于迁移学习的方法，利用英文丰富的知识填充中文信息框。该工作在本文中不涉及。

{\heiti 跨语言属性对齐}旨在匹配不同语言下对应信息框中的属性，多用在建立跨语言知识库，对迁移学习、补充属性模板等也有一定意义。

本文对属性的研究主要围绕属性抽取、相似属性查找、属性模板生成、跨语言属性对齐四点进行。


\section{现有知识库构建和相关技术}
\label{sec:knowledgebase-research}

随着语义网概念的普及与技术的发展，各种领域、不同规模的知识库层出不穷。发布在链接数据（LOD）上的知识库林林总总，既有限定领域的LinkedMDB\cite{erxleben2014introducing}、GeoNames\cite{wick2011geonames}，也有着著名的大型多语言知识库如Dbpedia、Freebase、Wikidata等。这些知识库为实现统一与共享全世界知识的远景做着不懈的努力。

除此之外，一些知名公司也在做着相关产品，比如知识图谱的领头羊——谷歌的Google Knowledge Graph\cite{singhal2012introducing}，微软研究院的EntityCube\cite{nie2012statistical}和Probase\cite{wu2012probase}，以及IBM的Watson项目\cite{ferrucci2012introduction}。国内也存在一些商业化的中文知识库，如搜狗“知立方”和百度“知心”。起初，商业领域对知识图谱的期望，主要在于优化搜索。与传统搜索引擎相比，基于知识图谱的搜索在两方面有所改变：1）从搜索字符串入手，对查询内容进行了语义上的分析，从而精准地理解用户意图，实现更为人性化的搜索；2）在返回结果方面，知识图谱可正确返回确切的实体或文本，并可额外提供系统的结构化相关信息，Search Engine Land称谷歌利用知识图谱，提供的是答案，而不仅仅是一堆链接\cite{sullivan2012google}。

随着知识图谱知识关联、可推理等特点逐渐浮出水面，其可用武之地已经不局限于搜索引擎。个性化推荐也成为企业建立知识图谱产品的出发点\cite{Burke00knowledge,aggarwal2016knowledge}，利用知识图谱的信息关联，能很容易的找出相似或相关实体，而正是推荐系统的目标。此外，基于知识图谱的推荐，也很好的解决了基于评分推荐所面临的冷启动问题。文献\cite{passant2010dbrec,kaminskas2012knowledge} 基于dbpedia建立音乐知识库，从地方兴趣的角度推荐音乐，文献［］xxx。除了产品推荐，实体推荐也适合建立在知识图谱上。Yahoo!创建名为Spark的实体推荐引擎\cite{blanco2013entity}，旨在用户搜索时，在结果右边栏上提供相关的其他实体，如搜索演员，推荐有合作关系的作品与其他演员。类似的功能，在谷歌搜索与百度搜索上也可看到。这一功能，可以增加用户选择，提高用户点击率。知识图谱在其他方向也存在应用可能，有不少企业利用知识图谱的语义关系，建立与查找基于用户的知识图谱，从而可以实现在社交网络上推荐好友\cite{venkataramani2012tao}，在信贷领域识别借贷人\footnote{http://www.slideshare.net/sfbiganalytics/bigdata-and-ai-in-p2-p-industry-knowledge-graph-and-inference}等功能。问答系统与信息抽取等也开始依赖知识图谱提供背景知识[引用]。

知识图谱的建立涉及很多挑战，包括知识抽取、多源知识融合、知识的推理与应用等。其中多源知识融合是比较困难的一个环节，因为不同数据源的数据构造规则不统一、人工编辑用语习惯不一致等问题，使得知识融合不能单纯合并即可，需要识别不同源中同一实体、同一属性，构建统一的Taxonomy等等，整个过程，需要自然语言处理、机器学习等很多关键技术的辅助。

下面通过描述几个知名或相关知识库的构建方法，相似解说知识库构建流程，这对我们构建跨语言知识图谱有很大参考意义。

\subsection{中文知识库}

Zhishi.me\cite{niu2011zhishi,wang2014publishing}是国内学术领域最早构造的中文知识库，它从三个大型中文在线百科，即中文维基、百度百科、互动百科中获取知识，共抽取了5,000,000个不同的实体。Zhishi.me抽取了百科中的摘要、超链接、分类等诸多信息，与实体组成RDF三元组。因为融合多个百科资源，Zhishi.me运用了匹配算法，跨百科寻找<owl:sameAs>关系，并考虑到了一词多义与一义多词的情况，总结来说，它主要通过对齐词条标题处理实体对齐，用重定向信息解决歧义问题。最后，Zhishi.me利用高精度的维基百科跨语言链接，与DBpedia对齐，达到扩充到LOD上的目的。

另一个中文知识库CKB\cite{wang2011building}，诞生于互动百科唯一一个数据源。该知识库首先从百科自带分类体系和信息框中定义并抽取出概念层次结构以及属性，构成知识库本体架构，之后用本体描述百科中的每个实例，所有实例与本体的关系共生成了520万RDF三元组。最后为避免知识库过于孤立，增加与外部的联系，CKB利用维基百科的跨语言链接，与DBpedia的实例相关联。最终获得19542个概念、2079个对象类型属性、302个数据类型属性以及802593个实例。

因为建立在独立百科上，CKB并没有面临实体对齐等复杂工作，取而代之的，CKB从本体构建出发，先给出明确、清晰的本体定义，再将实例挂到本体下。其构建思想与规模较小的专业领域本体构建有异曲同工之处，但使用自动化方法构建。此外，CKB着重关注数据质量，对互动百科的原有分类体系进行了去重、去环等操作，相对于Zhishi.me，工作更细致，内容更准确。

我们的跨语言知识库借鉴了Zhishi.me与CKB的构造理念，详细的构造流程在\ref{sec:}中会给出。

\subsection{多语言知识库YAGO}
本节以YAGO为主介绍多语言知识库，YAGO自2007年创建起，历经9年，已经更新三代。从xx的YAGO\cite{suchanek2007yago,suchanek2008yago}，到xx的YAGO2\cite{hoffart2013yago2}，再到以多语言为特色的YAGO3\cite{mahdisoltani2014yago3}，其更新历程也昭示着知识库的发展趋势。

{\heiti YAGO} 于2007年由Suchanek, F.M等人创建，在当时是第一个将WordNet\cite{fellbaum1998wordnet}与Wikipedia结合起来的知识库。其数据模型完全基于RDF标注，对模型的设计进行了详尽的描述与探讨，包括一对多关系、语义关系定义等问题，对其他知识库的建立有着很好的借鉴意义。在构建Taxonomy时，添加类型排查算法，保证YAGO的准确率达到95\%。YAGO含有约170万个实体，与1500万个关系事实。

{\henti YAGO2}是YAGO的扩展版本，在原版本的维护上，尝试整合更多的空间与时间纬度的关系事实，并融合了GeoNames知识库信息，通过规则定义\？其抽取的关系事实准确率高达95\%以上。YAGO2的知识数量扩展到980万个实体，44700万个关系事实。

以往的YAGO版本都是纯英文知识库，从YAGO3起，YAGO开始向多语言转换。YAGO3基于维基百科，添加了德语、法语、意大利语等10种语言，在跨语言对齐方面提出了简单却有效的方法，主要处理了关系事实与概念分类两部分。前者从各语言信息框中抽取属性-属性值关系，经过类型判断与功能冲突判断后，后者利用Wikidata信息，抽取现成的跨语言关系，受到Wikidata数量的局限。

%\subsection{基于海量网页数据的知识库}
%不同于以上提及的从百科的半结构化数据中生成知识库，微软研究院致力于从海量纯文本数据中自动抽取实体和is-A关系，整个构建过程涉及到基于规则、基于概率与机器学习思想。譬如，


\section{实体相关技术}
\label{sec:entity-research}

当前知识库的一个重要应用是实体链接(Entity Linking)。实体链接是链接网络文本数据与知识库的桥梁，其定义为：将文本中出现的命名实体文本链接到知识库中对应实体上。

它在很多不同领域中有所应用，比如信息抽取\cite{lin2012entity,nakashole2012patty}、文本分析\cite{gattani2013entity}、问答系统\cite{gattani2013entity,welty2012comparison}等等。TAC（Text Analysis Conference）将实体链接作为Knowledge Base Population（KBP）的一个子任务，并提供数据集供参赛者评测。

实现实体链接需要解决三个主要的子任务，分别为实体候选生成、实体候选排序、未链接文本预测。每个子任务都值得进一步探讨，下文从任务描述与常用解决思路方面对它们进行简单介绍。

{\heiti 实体候选生成} 旨在建立一个表现文本与知识库实体的对应关系，实体链接的任务往往是首选在文本中识别出表现文本，再进一步分析可能对应的实体。因此实体候选是决定能否链接的关键步骤。

通常情况下，实体候选集合从百科数据中抽取\cite{bunescu2006using,shen2012linden,shen2013linking}，维基百科中的词条名称、重定向页面、消歧页面、超链接等，都可以作为一个实体的表示文本。此外也有一些表示文本扩展方法被提出来，比如基于规则匹配\cite{han2009nlpr_kbp,lehmann2010lcc}，取公司首字母缩写、人名缩写等，以及有监督学习的方法\cite{zhang2011entity}。也有利用搜索引擎查询字符串扩展候选集的方法\cite{dredze2010entity, monahan2011cross}。

{\heiti 实体候选排序}是实体链接任务的关键步骤，给定一个表示文体，如果它对应多个实体，需要用排序算法进行消歧，确定具体需要的实体是哪一个。另外，所有的实体候选中，是否有指定的实体，也有待商榷。目前提出的排序模型主要分为监督排序方法与非监督排序方法。前者通过对训练数据集进行学习，预测给定候选是否是指定实体，包括二分类方法\cite{zhang2010entity,lehmann2010lcc,monahan2011cross,chen2011collaborative}、概率方法\cite{han2011generative}、基于图的方法\cite{han2011collective}。后者不需要预先标注的数据，方法包括向量空间模型（VSM）\cite{cucerzan2007large,han2009nlpr_kbp}，基于信息抽取的模型\cite{gottipati2011linking}等。

{\heiti 无链接文本预测}
有时，会面临给定一个表示文本，却不能在知识库中找到相应实体的问题，这是基于候选集合所必然出现的局限。一些研究默认实体候选包含了所有可能的表示文本，从而忽略了这个问题。但也有些解决方法被提出， ［交给大涛哥了。。。］

本文工作中，为跨语言知识库XLore开发了实体链接API，旨在为给定文本或实体提供相关语义信息，实现XLore可应用目标，力图在实践中完善知识库。

\section{本文研究目标和思路}
本文的总体目标为应用信息抽取、机器学习等方法，对跨语言的百科信息框属性进行模板生成与跨语言链接的匹配，并将结果应用到跨语言知识图谱上。重点针对英文维基与百度百科两个百科的异构性提出属性对齐流程与框架，力争抽取更多信息框属性，并提高跨语言对齐的召回率与准确率。在之后构建的知识库上，使用属性对齐结果丰富知识链接。最后为观察知识可用性，实现知识应用，开发展示系统与实体链接接口，以支持数据访问。下文将给出本文工作的主要思想与方法描述。

\subsection{基于百科的跨语言属性对齐}
\label{sec:}

\subsection{大规模中英文跨语言知识库XLore的构建}
\label{sec:}

\subsection{XLore系统与应用接口构建}
\label{sec:}

\section{本章小结}


