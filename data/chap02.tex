\chapter{研究现状}
\label{cha:research}
本章对知识库的发展现状和构建相关技术进行了调查与探讨，详细介绍了DBpedia等知名知识库，并对跨语言本体对齐技术进行了梳理总结。在这些研究的启发下，结合实际问题与切实数据情况，提出本体中概念属性生成与对齐方法。

\section{本章引论}
%自从Time Berner-Lee提出语义万维网的概念并规划出发展前景，语义网逐渐受到研究领域的关注，开始快速发展。通过语义万维网的直接目标：即让计算机理解语义文本，加强自动交流，可以预见语义网的建立要结合人工智能与Web技术。以自然语言处理、信息检索、机器学习为首的人工智能负责对纯文本进行分析、清理、语义理解、知识融合等工作，而Web技术则主导解析HTML文本，以及为知识关联与利用提供语义化环境等。从当前技术的发展趋势来看，作为人工智能与Web相结合的产物，语义网的出现，也是万维网发展的必然结果。

知识图谱作为语义网发展过程中的产物，最初由谷歌提出，是谷歌对其建立的知识库产品的称呼，现在这一名称被广泛用来指代大规模知识库。知识图谱涵盖大量实体，包括实例、概念、属性三类主要元素，一般以三元组的形式，即“主语-谓语-宾语”表示关系。一般来说，一个实例属于一个或多个概念，并含有多个属性，属性与属性值组成实例的关系事实，表征该实例的特性。知识图谱规模庞大，一般从多个数据源中精炼而成，包含一定杂质与错误。多源知识的关系抽取和自动融合，一直是知识图谱领域备受关注的研究点。本章对知识库研究现状进行讨论，列举比较典型的知识库，探讨其优缺点（详见\ref{sec:knowledgebase-research}节）。

基于海量数据分析构建知识图谱的一项重要任务获取关系事实\cite{suchanek2014knowledge}。关系事实表征着实例的属性及实例间的关系，如“清华大学—建校时间—1911 年”、“清华大学—现任校长—邱勇”，均为关系事实。规模较小的领域本体，因实体类型限制在一定领域，所涉及的属性数量有限，一般可以通过人工直接定义\cite{boyce2007developing}或人工筛选抽取结果\cite{wang:movie}来获得。然而以百科等大型数据集为来源的知识图谱，通常从页面信息框中提取关系事实与属性，数量在万级以上，杂质较多，准确度不能保证。因此，基于百科分类树与信息框属性构建的知识库本体需要进行检测、清理、对齐等处理。\ref{sec:ontology-research}节中将会从本体对齐、跨语言属性对齐等方面来阐述近些年对本体或信息框属性的研究，这些工作与知识库构建密切相关，对我们的概念属性工作有着很大的指导意义。

\section{知识库构建和相关技术}
\label{sec:knowledgebase-research}

随着语义网概念的普及与技术的发展，不同领域、不同规模的知识库层出不穷。发布在LOD上的知识库林林总总，既有DBpedia、Freebase、Wikidata等著名的大型多语言知识库，也有限定领域的LinkedMDB\cite{erxleben2014introducing}、GeoNames\cite{wick2011geonames}等。这些知识库为实现全球知识共享的远景做着不懈努力。

除此之外，一些知名公司也在做着相关产品，比如知识图谱的领头羊——谷歌的Google Knowledge Graph\cite{singhal2012introducing}，以及微软研究院的EntityCube\cite{nie2012statistical}和Probase\cite{wu2012probase}、IBM的Watson项目\cite{ferrucci2012introduction}。国内也涌现了一批商业化的中文知识库，如搜狗“知立方”和百度“知心”。商业领域对知识图谱的期望，主要在于优化搜索。与传统搜索相比，基于知识图谱的搜索在两方面有所改变：1）从搜索字符串入手，对查询内容进行了语义上的分析，从而精准地理解用户意图，实现更为人性化的搜索；2）在返回结果方面，知识图谱可精确返回确切的实体，并提供结构化的关联信息，Search Engine Land称谷歌利用知识图谱，提供的是答案，而不仅仅是一堆链接\cite{sullivan2012google}。

随着知识图谱知识关联、可推理等特点逐渐浮出水面，其用武之地已经不局限于搜索引擎，个性化推荐也成为企业建立知识图谱产品的出发点\cite{Burke00knowledge-basedrecommender,aggarwal2016knowledge}。利用知识图谱的信息关联，能很容易地找出相似或相关实体，很好地解决了基于评分推荐所面临的冷启动问题。文献\cite{passant2010dbrec}基于DBpedia建立音乐知识库，从地方兴趣的角度推荐音乐。除了产品推荐，实体推荐也是知识图谱的一项重要应用。Yahoo!开发了名为Spark的实体推荐引擎\cite{blanco2013entity}，旨在用户搜索时，提供相关的其他实体，如搜索演员时推荐有合作关系的作品与合作人，类似的功能在谷歌搜索与百度搜索上也可看到。此外，有不少企业利用知识图谱的语义关系，实现社交网络上的好友推荐\cite{venkataramani2012tao}，信贷领域的借贷人识别\footnote{\url{http://www.slideshare.net/sfbiganalytics/bigdata-and-ai-in-p2-p-industry-knowledge-graph-and-inference}}，以及知识图谱支持的自动问答等\cite{yih2015semantic,yang2014joint}。

知识图谱的建立涉及很多挑战，包括知识抽取、多源知识融合、知识的推理与应用等。其中多源知识融合是比较困难的一个环节，因为不同数据源的数据构造规则不统一、人工编辑用语习惯不一致等问题，使得知识融合不能单纯合并，需要识别不同源中同一实体、同一属性，找到对齐关系，构建统一的本体。整个过程，需要自然语言处理、机器学习等诸多关键技术的辅助。

下面通过描述几个知名知识库的构建方法，介绍知识库构建思路，这对我们构建跨语言知识图谱有很重要的参考意义。

\subsection{中文知识库}

Zhishi.me\cite{niu2011zhishi,wang2014publishing}是国内学术领域最早构造的中文知识库，它从三个大型中文在线百科，即中文维基、百度百科、互动百科中获取知识，共抽取了500万个不同实体，包含百科中的摘要、超链接、分类等诸多信息，组成RDF三元组。因为融合多个百科资源，Zhishi.me运用了匹配算法跨百科寻找匹配关系，主要通过词条标题处理实体对齐，用重定向信息解决歧义问题。最后，Zhishi.me利用维基百科现有跨语言链接对齐到DBpedia，与LOD数据集关联。

另一个中文知识库CKB\cite{wang2011building}基于互动百科构建。该知识库首先从百科自带分类体系和信息框中定义并抽取出概念层次结构以及属性，构成知识库本体架构，然后用本体描述百科中的每个实例，共生成了520万RDF三元组，包含19542个概念、2079个对象类型属性、302个数据类型属性以及80万个实例。最后，CKB同样利用维基百科的跨语言链接与DBpedia的实例相关联。建立在独立百科上的CKB并没有面临实体对齐等复杂工作，其构建思想是从本体出发，先给出明确、清晰的本体定义，再将实例挂到本体下，与规模较小的专业领域本体构建有异曲同工之处，但过程自动化。此外，CKB着重关注数据质量，对互动百科的原有分类体系进行了去重、去环等操作，相对于Zhishi.me，工作更细致，内容更准确。

我们的跨语言知识库XLore借鉴了Zhishi.me与CKB的构造理念，其构造流程在章节\ref{sec5:cross-lingual-knowledge-base}中给出介绍。

\subsection{多语言知识库}
DBpedia作为跨语言知识库的代表，最初版本在2007年发布\cite{auer2007dbpedia}，是一个完全基于维基百科数据构建的多语言、跨领域知识库，注重于对实体、摘要等的提取，包含13个语言，共195万实体。之后DBpedia加强了对信息框的处理，提出DBpedia映射\footnote{\url{http://mappings.dbpedia.org/index.php/Main_Page}}解决信息框模板中属性一义多词的问题。目前DBpedia已经涵盖97个语言的知识，24.6亿个RDF三元组，成为LOD的核心。已有多个外部数据库或资料集与其相连，包括GeoNames、DBLP、Musicbrainz等。除此之外，DBpedia也作为诸多应用的基础数据支持，包括TAC-KBP\cite{mendes2011evaluating}的实体链接任务、音乐推荐\cite{passant2010dbrec}等。

%鉴于维基百科在信息框以及模板上的定义多元化，这一改善映对语言的机制，多是经过人工参与的。首先定义一个本体schema，再将维基信息框属性映射上去\cite{mendes2012dbpedia}。

%\subsection{多语言知识库YAGO}
另一个著名的多语言知识库YAGO创建至今，9年间已经更新三代。从最初的YAGO\cite{suchanek2007yago,suchanek2008yago}，到关系事实扩展的YAGO2\cite{hoffart2013yago2}，再到以多语言为特色的YAGO3\cite{mahdisoltani2014yago3}，其更新历程也是知识库发展趋势的一个缩影。
\begin{itemize}
  \item {\heiti YAGO}首次将WordNet\cite{fellbaum1998wordnet}与Wikipedia结合。其数据模型完全基于RDF标准，模型设计中详尽地描述与探讨了一对多关系、语义关系定义等问题，对其他知识库的建立有着很好的借鉴意义。在构建分类体系时，添加类型排查算法，保证YAGO的准确率达到95\%。YAGO含有约170万个实体，与1500万个关系事实。
  \item {\heiti YAGO2}是YAGO的扩展版本，在原版本基础上整合了更多的空间与时间维度的关系事实，并融合了GeoNames知识库信息，知识数量扩展到980万个实体，44700万个关系事实。
  \item 以往的YAGO版本都是纯英文知识库，{\heiti YAGO3}开始向多语言转换。YAGO3基于维基百科，扩充了德语、法语等10种语言，在跨语言对齐方面对关系事实与概念分类提出了简单却有效的方法。前者从各语言信息框中抽取属性—属性值关系，经过类型判断与功能冲突判断后对齐属性；后者利用Wikidata中现有的跨语言关系，对齐数量受到Wikidata存储量的局限。
\end{itemize}

\section{本体对齐相关研究}
\label{sec:ontology-research}

本体是一个领域的术语集合，是对领域的描述，是知识库的“骨架”。多个本体或知识库要合并时往往会出现{\heiti 语义异构}现象，即不同本体对于同一概念的表达有偏差，不可直接合并。本体对齐就是致力于解决语义异构问题的研究。另外，本体的表示也不仅仅局限于一种语言上，当涉及多种语言下的本体融合时，还需要解决跨语言本体对齐问题。本节从同语言的异构本体对齐、跨语言本体对齐方面分类总结，并重点介绍信息框属性的相关研究。

\subsection{异构本体对齐}
常见的同语言本体匹配方法可以归纳为：

{\heiti 基于相似度的方法}，即通过计算两个实体的相似度，选择相似度最大的作为匹配结果。字符串相似度对比是比较常见的方法，其中，编辑距离、N-gram距离等较为常用。也有通过语义信息来计算的方法，WordNet\cite{miller1995wordnet}在该方法中被广泛应用。 
另有利用结构信息，较为简单的方法是利用本体自带的限制信息，如定义域或值域的相关程度。文献\cite{hu2008matching}将实体关系看作图，利用图结构进行比较。
也有利用本体关系进行相似度传播的算法，该方法需要一批已经匹配的种子集合，根据临近实体也可能很相似的假设，寻找更多匹配对。

{\heiti 基于知识库背景的方法}，即通过当前本体中实体的背景信息，或从其他大规模知识库中找到对应实体及其背景关系，并认为背景相似的实体很可能匹配。SAMBO\cite{lambrix2006sambo}利用知识库UMLS提供背景知识，对生物领域内的本体进行对齐。文献\cite{wartena2008instanced}则利用网络标注信息构建本体对齐方法。

{\heiti 基于机器学习的方法\cite{niepert2010probabilistic,albagli2012markov}}，即将匹配问题抽象为分类或优化问题，引入分类算法、概率模型等机器学习方法解决问题。

\subsection{跨语言本体对齐}
当前跨语言本体对齐可以归结为几类，分别为人工处理\cite{liang2006mapping}, 基于语料对齐\cite{ngai2002identifying}, 间接对齐\cite{jung2009indirect}，基于翻译对齐\cite{zhang2008rimom,wang2009matching}等等。 文献\cite{liang2006mapping}中，中英文语料库的对齐直接通过人工标注，这种方法虽然准确率有保障，对大型本体的处理会相当费时。文献\cite{ngai2002identifying}用一个双语语料对齐英文WordNet与中文HowNet，这种方法受语料局限，无法通用。文献\cite{jung2009indirect}提出了间接对齐方法，即通过对齐本体$O_1$与$O_2$，对齐本体$O_2$与$O_3$，实现$O_1$与$O_3$的对齐。 
基于标签翻译的方法比较常见，该方法先将源语言翻译到目标语言，然后在单语言上运用结构对齐、词汇对齐等方法实现跨语言对齐。RiMOM系统\cite{zhang2008rimom}在2008年的OAEI测试中使用基于翻译的方法对齐英日本体。文献\cite{wang2009matching}通过谷歌翻译服务首先做了实体词典，之后用基于实例的方法实现英、法、德三语言的主语对齐。

\subsection{信息框属性对齐}
\label{sec:property-research}
属性是本体重要的组成部分，一般本体、尤其领域本体中定义的属性较少，通常通过人工检查对齐即可\cite{wang:movie}，而通过在线百科构建的知识库，其中本体多从信息框中抽取生成，数量较多。当前已有大量针对信息框与属性的研究，主要包括属性抽取、相似属性查找、信息框填充、跨语言属性对齐等方向。

{\heiti 属性抽取}指从普通文本或结构化数据中抽取属性对工作，通常基于词法—句法规则匹配方法\cite{pacsca2007role,lee2013attribute}，或从网页表格或列表中通过$\langle td\rangle$，$\langle li\rangle$等标签获得\cite{crestan2010web}，并且通过不同的测量方法过滤掉错误结果，如基于出现频率\cite{pacsca2007role}、人工规则\cite{lee2013attribute}等。本文针对维基百科特点，给出基于信息框属性的抽取过程，将在章节\ref{sec:property-extraction}中详细说明。

{\heiti 相似属性查找}的目标是将表示相同意义的属性找出并合并。最简单的思想是利用字符串相似度匹配方法比较属性标签，常见的算法有余弦相似度算法、Jaccard距离算法、编辑距离等。
其他的衡量方法依赖已有的知识资源（如WordNet）\cite{yang2005measuring}，或者语境分布\cite{pantel2009web}。
大部分寻找同义属性的工作都是基于英文的，中文相关工作较少。并且，由于中文方块字特征（如没有大小写区分、没有空格等），基于中文属性的工作则更加困难。文献\cite{liu2014extracting}以百度百科为数据源，结合文本相似度、语义相似度、上下文相似度，寻找中文相似属性。

{\heiti 信息框填充}可以看作是信息抽取问题，从词条文本中抽取主语-关系-宾语三元组，为缺失属性抽取属性值。KYLIN\cite{wu2007autonomously}是第一个解决信息框缺失问题的系统，它使用自监督方法，在训练数据足够时效果不错。WikiCiKE\cite{wang2013transfer}在跨语言数据集上，使用基于迁移学习的方法，利用英文丰富的知识填充中文信息框。

{\heiti 跨语言属性对齐}旨在匹配不同语言下对应信息框中的属性。当前常见方法为在维基百科已知的对齐词条下，通过对属性值的比较，对齐同一属性。其中基于字母系统的语言比较起来相对容易，可以直接利用字符串相似度计算等方法\cite{bouma2009cross}。而英语与方块字的对齐往往要经过翻译工具辅助\cite{fu2009cross}，文献\cite{nguyen2011multilingual}则利用维基百科的跨语言链接构成词典对，辅助中英文转换。

判定对齐分为非监督方法与监督方法，前者通过数据特性，在标签文本、链接结构、共现性、值域范围等方面指定相似计算方法与基准，保留可能性大的匹配对\cite{nguyen2011multilingual,lin2011unsupervised}；后者将问题抽象成是否匹配的二分类问题\cite{adar2009information}，通过设定特征集合训练模型获得准确结果。另外因为受到已对齐词条的局限，也有先找到更多跨语言词条，进而增加对齐属性数量的方法\cite{rinser2013cross}，或者通过已对齐属性扩展对齐词条，进而迭代处理属性的方法\cite{nguyen2013slint+}。

维基百科的模板特性影响着人们对于属性的定义，属性对齐过程中，应该在何种粒度上操作？大部分研究认为标签相同则为同一属性\cite{adar2009information,nguyen2011multilingual}，也有将不同模板下的属性区分开来\cite{bouma2009cross}。本文认为不同概念下的属性表征含义不同，通过模板抽象出概念区分属性。

\section{本文研究目标和思路}
本文总体目标为应用信息抽取、机器学习等方法，对跨语言异构百科信息框属性进行概念属性生成与对齐，并将结果应用到跨语言知识图谱构建上。重点对中英文维基生成概念属性，针对英文维基与百度百科的异构性提出属性对齐流程与框架，致力于获得更多信息框属性。在构建知识库过程中使用属性对齐结果丰富知识链接。最后为观察知识可用性，实现知识应用，开发展示系统与实体链接接口，以支持数据访问。下文将给出本文工作的主要思想与方法描述。

\subsection{基于维基百科的概念属性生成}
属性作为知识库本体中的重要元素，与概念有着密切关系，用来描述概念下的实例特性，而不同概念的性质不尽相同。属性在不同概念下具有歧义性（相同名称的属性，可能指代不同的意思），如名称为\textit{产地}的属性，在电影领域中是\textit{制作国家}的意思，而在植物领域中是\textit{生长地点}的意思。将属性受限于概念领域可以对属性进行精确的区分。

维基百科通过{\heiti 信息框模板}规范着对同一领域的实体的描述规则，模板中的属性为一类实体的特性，与概念属性很相近。通过分析维基百科模板，利用模式匹配，我们获得了一系列概念，以及概念下的属性集合(详见第\ref{cha:concept-property}章)。

%在属性抽取一步，百度百科的网页结构化信息较为容易处理，但维基百科信息框所依据的模板，定义却不统一。通过对维基百科模板的观察，我们为不同的模板定义提供了相应的抽取规则，将可能获得维基百科信息框模板与属性数量最大化（详见\ref{sec:property-extraction}）。

\subsection{基于异构百科的跨语言属性对齐}
大部分对跨语言属性对齐的研究都在维基百科上进行，
%维基百科丰富的知识储备、多语言的特性，有利于研究者探寻数据规律与特征。
然而，中英文维基知识相差悬殊，无论是词条还是信息框，数量都不对称。要想尽可能多地获得中文属性与跨语言关系，需要其他中文百科的辅助。

本文的工作重点为异构百科上的跨语言属性链接。为解决引入多源数据所面临的异构特性带来的百科规则的不同、人员编辑习惯的迥异等问题，我们对维基百科与百度百科的模板与属性的异同进行了详细的分析（详见\ref{sec:template-property-analysis}）。

我们提出跨语言属性对齐框架（详见\ref{sec:property-matching}），跨语言对齐被看作是一个二分类问题，为达到更精确的结果与更高的召回率，我们首先对齐同语言信息，为跨语言做好铺垫；抽取跨语言种子，避免人工标注。

针对没有模板的百度百科，首先圈定概念与属性集合，形成领域模板，在概念上先行对齐。此后，属性的分析在模板范围之内进行，减小了搜索空间，使算法运行效率有所提高（详见\ref{sec:domain-template}）。

概念属性避免了一词多义，但属性还存在一义多词现象，即描述相同意义的属性，有不同的写法。比如电影\textit{上映时间}有\textit{首映时间}等多种写法，这种现象多是由于编辑者个人写作习惯不同所造成。找出同领域的这些同义词，有助于丰富链接知识。
%我们从文本相似度、语义相似度等方面出发，计算同领域的属性集合中的两两相似性，将相似性高的属性合并成同一个属性（详见\ref{sec:similar-property}）
我们通过多策略对齐中文维基与百度百科，找到维基属性与百度属性的一对多关系，从而获得相似属性（详见\ref{sec:similar-property}）。

得益于维基百科的多语言特性，通过模板对齐、属性值匹配等方法，可预先获得一批精准度高的属性跨语言对齐关系。但以中英文维基对齐属性为桥梁匹配的维基与百度百科属性，仅是一小部分，因为百科异构性，还有大量的中英文跨百科属性有待具体分析。这批初始的跨语言对齐属性，将作为进一步抽取更多属性对齐关系的种子集合。这一步更避免了监督学习常见的训练集合的标注问题（详见\ref{sec:cross-lingual-seed}）。

以上几个模块在一定程度上削减了百科异构性带来的阻碍。相对于字母系统语言下的属性对齐研究，中文与英文在写法上大相径庭，不可单纯依赖文本相似度。本文将跨语言属性对齐看作二分类问题，除了使用文本特征，还提出几项假设，比如同一属性的使用流行度相似、同一属性的对象值指代同一个实体等，从结构维度抽取跨语言对的特征，辅助扩展跨语言链接的实现（详见\ref{sec:cross-lingual-property-matching}）。

\subsection{XLore系统与应用接口构建}
本文以解决中文知识匮乏现象、提供中英文链接知识为出发点，构建跨语言知识库XLore。为了能直观地观察数据，我们为XLore搭建网页展示系统。提供开放式的数据访问，包括点击访问、搜索框查询、SPAQL语句查询、关系可视化等。从应用的角度，还搭建了基于知识库的实体链接查询接口，供文本相关研究调用（详见第\ref{cha:xlore}章）。
%基于当今知识库的构建思想，我们以维基百科、百度百科、互动百科为数据源，从异构结构中抽取实例、概念、属性构成知识库。跨语言链接是融合多语言知识库的根本要素，我们对三类元素的链接分别进行了扩展，丰富了跨语言关系。
%之后将结构化数据转换成RDF三元组，构成标准知识库

\section{本章小结}
本章首先从知识图谱的应用角度介绍了其重要性，梳理了涉及的问题与相关技术，包括中文及跨语言知识库构建、本体对齐以及信息框属性研究。总结了相关研究的优势和不足，并结合本文工作的特色，凝练了研究目标和问题，形成自己的问题解决思路，提出具体解决方案。
