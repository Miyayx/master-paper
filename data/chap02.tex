\chapter{研究现状}
\label{cha:research}
本章对当前知识库的发展现状与构建相关技术进行了研究与探讨，对几个知名知识库给出了详细介绍，并主要对跨语言本体对齐技术进行了说明，在这些研究的启发下，结合实际问题与切实数据情况，提出属性对齐方法与跨语言知识库的构建流程。此外，从应用角度，尤其是实体链接方面的研究点进行了调研。

\section{本章引论}
自从Time Berner-Lee提出语义万维网的概念并规划出发展前景，语义网逐渐受到研究领域的关注，开始快速发展。通过语义万维网的直接目标：即让计算机理解语义文本，加强自动交流，可以预见语义网的建立要结合人工智能与Web技术。以自然语言处理、信息检索、机器学习为首的人工智能负责对纯文本进行分析、清理、语义理解、知识融合等工作，而Web技术则主导解析HTML文本，以及为知识关联与利用提供语义化环境等。从当前技术的发展趋势来看，作为人工智能与Web相结合的产物，语义网的出现，也是万维网发展的必然结果。

知识图谱是语义网发展过程中的产物。这一概念最初由谷歌提出，是谷歌对其建立的知识库产品的称呼，其作用为理解用户搜索内容，从更深、更广的角度提供一个全面的搜索结果。现在这一名称被广泛用来指代大规模知识库。知识图谱涵盖大量实体，同时以RDF三元组，即主语-谓语-宾语的形式存储着与实体与其他实体、概念、属性之间的关系。一般来说，一个实体属于一个或多个概念，还含有多个facts，表征该实体的特性。与精准度高的本体不同的是，知识图谱规模庞大，一般从多个数据源中精炼而成，具有一定的容错性，如何自动融合多源知识，如何提取正确关系，一直是知识图谱不可避免的阻碍，也是该领域广受关注的研究点。发布于开放链接(LOD)项目中的大规模开放数据集，都可称之为知识图谱。本章将对现今知识库现状进行讨论，并列举比较典型或相关的知识库，探讨其优缺点（详见\ref{sec:knowledgebase-research}），并从实体的角度，介绍其目前常见问题与应用（详见\ref{sec:entity-research}）。

针对从海量数据分析中构建知识图谱这一问题，YAGO作者在文献\cite{suchanek2014knowledge} 中提及，其中一项有着重要意义的工作为获取关系事实。关系事实表征着实体的属性，以及实体与其他实体的关系，比如“清华大学-现任校长-邱勇”，即为一个关系事实。规模较小的领域本体，因实体类型限制在一定领域，其涉及的属性也屈指可数，一般可以通过人工直接定义\cite{boyce2007developing}或人工抽取\cite{wang:movie}来获得。然而以百科等大型数据集为来源的知识图谱，通常从页面信息框中提取关系事实与属性，数量在万级以上，杂质较多，准确度不能保证。因此，基于百科分类树与信息框属性构建的本体需要进行检测、清理、对齐等处理，基于此，对本体的研究也数不胜数。\ref{sec:ontology-research} 中将会从本体对齐、跨语言属性对齐等方面来阐述近些年对百科分类或信息库属性的研究，这些工作与知识库构建息息相关，对我们的概念属性工作有着很大的指导意义。

\section{现有知识库构建和相关技术}
\label{sec:knowledgebase-research}

随着语义网概念的普及与技术的发展，各种领域、不同规模的知识库层出不穷。发布在LOD上的知识库林林总总，既有限定领域的LinkedMDB\cite{erxleben2014introducing}、GeoNames\cite{wick2011geonames}，也有着著名的大型多语言知识库如Dbpedia、Freebase、Wikidata等。这些知识库为实现统一与共享全世界知识的远景做着不懈的努力。

除此之外，一些知名公司也在做着相关产品，比如知识图谱的领头羊——谷歌的Google Knowledge Graph\cite{singhal2012introducing}，微软研究院的EntityCube\cite{nie2012statistical}和Probase\cite{wu2012probase}，以及IBM的Watson项目\cite{ferrucci2012introduction}。国内也存在一些商业化的中文知识库，如搜狗“知立方”和百度“知心”。起初，商业领域对知识图谱的期望，主要在于优化搜索。与传统搜索引擎相比，基于知识图谱的搜索在两方面有所改变：1）从搜索字符串入手，对查询内容进行了语义上的分析，从而精准地理解用户意图，实现更为人性化的搜索；2）在返回结果方面，知识图谱可正确返回确切的实体或文本，并可额外提供系统的结构化相关信息，Search Engine Land称谷歌利用知识图谱，提供的是答案，而不仅仅是一堆链接\cite{sullivan2012google}。

随着知识图谱知识关联、可推理等特点逐渐浮出水面，其可用武之地已经不局限于搜索引擎。个性化推荐也成为企业建立知识图谱产品的出发点\cite{Burke00knowledge,aggarwal2016knowledge}，利用知识图谱的信息关联，能很容易的找出相似或相关实体，而正是推荐系统的目标。此外，基于知识图谱的推荐，也很好的解决了基于评分推荐所面临的冷启动问题。文献\cite{passant2010dbrec,kaminskas2012knowledge} 基于dbpedia建立音乐知识库，从地方兴趣的角度推荐音乐，文献\cite{jiang2005multimedia}为在线用户推荐产品，文献\cite{cheekula2015entity}基于垂直领域知识库进行电影推荐。除了产品推荐，实体推荐也适合建立在知识图谱上。Yahoo!创建名为Spark的实体推荐引擎\cite{blanco2013entity}，旨在用户搜索时，在结果右边栏上提供相关的其他实体，如搜索演员，推荐有合作关系的作品与其他演员。类似的功能，在谷歌搜索与百度搜索上也可看到。这一功能，可以增加用户选择，提高用户点击率。知识图谱在其他方向也存在应用可能，有不少企业利用知识图谱的语义关系，建立与查找基于用户的知识图谱，从而可以实现在社交网络上推荐好友\cite{venkataramani2012tao}，在信贷领域识别借贷人\footnote{http://www.slideshare.net/sfbiganalytics/bigdata-and-ai-in-p2-p-industry-knowledge-graph-and-inference}等功能。问答系统等也开始依赖知识图谱提供背景知识\cite{yih2015semantic,yang2014joint}。

知识图谱的建立涉及很多挑战，包括知识抽取、多源知识融合、知识的推理与应用等。其中多源知识融合是比较困难的一个环节，因为不同数据源的数据构造规则不统一、人工编辑用语习惯不一致等问题，使得知识融合不能单纯合并即可，需要识别不同源中同一实体、同一属性，找到对齐关系，构建统一的本体，整个过程，需要自然语言处理、机器学习等诸多关键技术的辅助。

下面通过描述几个知名知识库的构建方法，详细说明知识库构建流程，这对我们构建跨语言知识图谱有很大参考意义。

\subsection{中文知识库}

Zhishi.me\cite{niu2011zhishi,wang2014publishing}是国内学术领域最早构造的中文知识库，它从三个大型中文在线百科，即中文维基、百度百科、互动百科中获取知识，共抽取了5,000,000个不同的实体。Zhishi.me抽取了百科中的摘要、超链接、分类等诸多信息，与实体组成RDF三元组。因为融合多个百科资源，Zhishi.me运用了匹配算法，跨百科寻找<owl:sameAs>关系，并考虑到了一词多义与一义多词的情况，总结来说，它主要通过对齐词条标题处理实体对齐，用重定向信息解决歧义问题。最后，Zhishi.me利用高精度的维基百科跨语言链接，与DBpedia对齐，达到扩充到LOD上的目的。

另一个中文知识库CKB\cite{wang2011building}，诞生于互动百科唯一一个数据源。该知识库首先从百科自带分类体系和信息框中定义并抽取出概念层次结构以及属性，构成知识库本体架构，之后用本体描述百科中的每个实例，所有实例与本体的关系共生成了520万RDF三元组。最后为避免知识库过于孤立，增加与外部的联系，CKB利用维基百科的跨语言链接，与DBpedia的实例相关联。最终获得19542个概念、2079个对象类型属性、302个数据类型属性以及802593个实例。

因为建立在独立百科上，CKB并没有面临实体对齐等复杂工作，取而代之的，CKB从本体构建出发，先给出明确、清晰的本体定义，再将实例挂到本体下。其构建思想与规模较小的专业领域本体构建有异曲同工之处，但使用自动化方法构建。此外，CKB着重关注数据质量，对互动百科的原有分类体系进行了去重、去环等操作，相对于Zhishi.me，工作更细致，内容更准确。

我们的跨语言知识库XLore借鉴了Zhishi.me与CKB的构造理念，其构造流程在\ref{sec5:cross-lingual-knowledge-base}中给出介绍。

\subsection{多语言知识库DBpedia}
DBpedia作为跨语言知识库的代表，最初版本在2007年发布\cite{auer2007dbpedia}，是一个完全基于维基百科数据构建的多语言、跨领域知识库，注重于对实体、摘要等的提取，包含13个语言，共195万实体，此外也对信息框采用模式匹配，获得大量三元组。

之后DBpedia加强了对信息框的处理，提出DBpedia映射\footnote{\url{http://mappings.dbpedia.org/index.php/Main_Page}}解决信息框模板中相同属性不同表达的问题，鉴于维基百科在信息框以及模板上的定义多元化，这一改善映对语言的机制，多是经过人工参与的。首先定义一个本体schema，再将维基信息框属性映射上去\cite{mendes2012dbpedia}。

目前DBpedia已经涵盖97个语言的知识，24.5亿笔RDF三元组，成为LOD的核心。已有多个外部数据库或资料集与其相连，包括GeoNames、DBLP、Musicbrainz等，BBC也使用DBpedia来辅助其内容组织。除此之外，DBpedia也作为诸多应用的基础数据支持，包括TAC-KBP\cite{mendes2011evaluating}的实体链接任务、音乐推荐\cite{passant2010dbrec}等。

\subsection{多语言知识库YAGO}
YAGO自2007年创建起，历经9年，已经更新三代。从最初的YAGO\cite{suchanek2007yago,suchanek2008yago}，到关系事实扩展的YAGO2\cite{hoffart2013yago2}，再到以多语言为特色的YAGO3\cite{mahdisoltani2014yago3}，其更新历程也昭示着知识库的发展趋势。

{\heiti YAGO} 于2007年由Suchanek, F.M等人创建，在当时是第一个将WordNet\cite{fellbaum1998wordnet}与Wikipedia结合起来的知识库。其数据模型完全基于RDF标注，对模型的设计进行了详尽的描述与探讨，包括一对多关系、语义关系定义等问题，对其他知识库的建立有着很好的借鉴意义。在构建Taxonomy时，添加类型排查算法，保证YAGO的准确率达到95\%。YAGO含有约170万个实体，与1500万个关系事实。

{\heiti YAGO2}是YAGO的扩展版本，在原版本的维护上，尝试整合更多的空间与时间纬度的关系事实，并融合了GeoNames知识库信息，知识数量扩展到980万个实体，44700万个关系事实。

以往的YAGO版本都是纯英文知识库，{\heiti YAGO3}开始向多语言转换。YAGO3基于维基百科，添加了德语、法语、意大利语等10种语言，在跨语言对齐方面提出了简单却有效的方法，主要处理了关系事实与概念分类两部分。前者从各语言信息框中抽取属性-属性值关系，经过类型判断与功能冲突判断后，xxxx；后者利用Wikidata信息，抽取现成的跨语言关系，受到Wikidata数量的局限。

\section{本体对齐相关研究}

本体是一个领域的术语集合，是对领域的描述，它是知识库的骨架部分。当有多个本体或知识库要合并成一个应用时，往往会出现{\heiti 语义异构}现象，即不同本体对于同一个概念的表达有偏差，直接合并不可行。本体对齐就是致力于解决语义异构问题。目前已经有很多解决方法提了出来，本节将从同语言的异构本体对齐、跨语言本体对齐方面进行阐述，同时重点介绍一下信息框属性的相关研究。

\subsection{异构本体对齐}
常见的本体匹配方法可以归纳为：

{\heiti 基于文本的方法}，即比较两个词语的相似度。字符串相似度对比是比较常见的方法，其中，编辑距离、N-gram距离等较为常用。此外也有通过语义信息来计算的方法，WordNet\cite{miller1995wordnet}在该方法中被广泛应用。
{\heiti 基于结构的方法\cite{hu2008matching}}，即利用本体构成的图关系来进行比较。较为简单的方法是利用本体自带的限制信息，如定义域或值域的相关程度。另外也有利用本体关系进行相似度传播的算法，该方法需要一批已经匹配的种子集合，根据\textit{临近实体也可能很相似的假设，寻找更多匹配对}。
{\heiti 基于领域知识库的方法\cite{ponzetto2009large,gligorov2007using}}，领域知识库为实体提供了背景信息，并认为背景相似的实体可能匹配。
{\heiti 基于机器学习的方法\cite{niepert2010probabilistic,albagli2012markov}}，即将匹配问题抽象为分类或优化问题，引入分类算法、概率模型等机器学习方法解决问题。

%当前已经得益于OAEI(Ontology Alignment Evaluation Initiative)比赛

\subsection{跨语言本体对齐}

\subsection{信息框属性对齐}
\label{sec:property-research}
在线百科的信息框融合了很多重要的、结构化信息。信息框是有一个实体的属性-属性值对罗列组成，这些信息对包含了该实体总结性信息。如果能充分利用这些信息，可以在xx方面有所突破。当前已有大量针对信息框与属性的研究，主要包括属性抽取\cite{}、相似属性查找、属性模板生成、信息框填充、跨语言属性对齐等等方向。

{\heiti 属性抽取}指从普通文本或结构化数据中抽取属性对工作，通常基于词法-句法规则匹配方法\cite{pacsca2007role,lee2013attribute}，或从网页table或list中通过$\langle td\rangle>$，$\langle li\rangle>$等标签获得\cite{crestan2010web}，并且通过不同的测量方法过滤掉错误的抽取对，如基于出现频率\cite{pacsca2007role}、人工规则\cite{lee2013attribute} 等。本文针对维基百科的模板特点，给出基于Infobox、表格、与继承模板三种类型的抽取过程，将在\ref{sec:}中详细说明。

{\heiti 相似属性查找}的目标是将表示相同意义的属性找出并合并成一组。此工作可以转换成寻找相似字符串的问题，最简单的思想是利用字符串相似度匹配方法，常见的算法有

余弦相似度算法

Jaccard距离算法

编辑距离

其他的衡量方法依赖已有的知识资源（如WordNet）\cite{yang2005measuring}，或者语境分布\cite{pantel2009web}。

大部分寻找同义属性的工作都是基于英文的，中文相关工作较少。并且，由于中文方块字特征（如没有大小写区分、没有空格等），基于中文属性的工作则更加困难。文献\cite{liu2014extracting}以百度百科为数据源，结合文本相似度、语义相似度、上下文相似度，寻找中文相似属性。与本文的工作相似。

{\heiti 属性模板生成}通过

{\heiti 信息框填充}可以看作是信息抽取问题，从词条文本中抽取主语-关系-宾语三元组，为缺失属性抽取属性值。KYLIN\cite{wu2007autonomously}是第一个解决信息框缺失问题的系统，它使用自监督方法，在训练数据足够时效果不错。WikiCiKE\cite{wang2013transfer} 在跨语言数据集上，使用基于迁移学习的方法，利用英文丰富的知识填充中文信息框。该工作在本文中不涉及。

{\heiti 跨语言属性对齐}旨在匹配不同语言下对应信息框中的属性，多用在建立跨语言知识库，对迁移学习、补充属性模板等也有一定意义。

本文对属性的研究主要围绕属性抽取、相似属性查找、属性模板生成、跨语言属性对齐四点进行。


\section{实体相关技术}
\label{sec:entity-research}

当前知识库的一个重要应用是实体链接(Entity Linking)。实体链接是链接网络文本数据与知识库的桥梁，其定义为：将文本中出现的命名实体文本链接到知识库中对应实体上。

它在很多不同领域中有所应用，比如信息抽取\cite{lin2012entity,nakashole2012patty}、文本分析\cite{gattani2013entity}、问答系统\cite{gattani2013entity,welty2012comparison}等等。TAC（Text Analysis Conference）将实体链接作为Knowledge Base Population（KBP）的一个子任务，并提供数据集供参赛者评测。

实现实体链接需要解决三个主要的子任务，分别为实体候选生成、实体候选排序、未链接文本预测。每个子任务都值得进一步探讨，下文从任务描述与常用解决思路方面对它们进行简单介绍。

{\heiti 实体候选生成} 旨在建立一个表现文本与知识库实体的对应关系，实体链接的任务往往是首选在文本中识别出表现文本，再进一步分析可能对应的实体。因此实体候选是决定能否链接的关键步骤。

通常情况下，实体候选集合从百科数据中抽取\cite{bunescu2006using,shen2012linden,shen2013linking}，维基百科中的词条名称、重定向页面、消歧页面、超链接等，都可以作为一个实体的表示文本。此外也有一些表示文本扩展方法被提出来，比如基于规则匹配\cite{han2009nlpr_kbp,lehmann2010lcc}，取公司首字母缩写、人名缩写等，以及有监督学习的方法\cite{zhang2011entity}。也有利用搜索引擎查询字符串扩展候选集的方法\cite{dredze2010entity, monahan2011cross}。

{\heiti 实体候选排序}是实体链接任务的关键步骤，给定一个表示文体，如果它对应多个实体，需要用排序算法进行消歧，确定具体需要的实体是哪一个。另外，所有的实体候选中，是否有指定的实体，也有待商榷。目前提出的排序模型主要分为监督排序方法与非监督排序方法。前者通过对训练数据集进行学习，预测给定候选是否是指定实体，包括二分类方法\cite{zhang2010entity,lehmann2010lcc,monahan2011cross,chen2011collaborative}、概率方法\cite{han2011generative}、基于图的方法\cite{han2011collective}。后者不需要预先标注的数据，方法包括向量空间模型（VSM）\cite{cucerzan2007large,han2009nlpr_kbp}，基于信息抽取的模型\cite{varma2009iiit,gottipati2011linking}等。

{\heiti 无链接文本预测}是指：给定一个表示文本，知识库中没有对应实体的问题，这是基于候选集合所必然出现的局限。一些研究默认实体候选包含了所有可能的表示文本，从而忽略了这个文本\cite{cucerzan2007large,kulkarni2009collective,shen2012liege}，一些研究则给出处理措施：如果所给文本在实体候选中没有匹配，就返回NIL\cite{varma2009iiit}。也有系统对于返回实体进行了更为慎重的筛选，即设定一个阈值，如果实体的可能性小于这个阈值，那即便它是最佳候选，也不认为它是所需求的实体\cite{han2009nlpr_kbp,lehmann2010lcc,han2011generative}。

本文工作中，为跨语言知识库XLore开发了实体链接API，旨在为给定文本或实体提供相关语义信息，实现XLore可应用目标，力图在实践中完善知识库。

\section{本文研究目标和思路}
本文的总体目标为应用信息抽取、机器学习等方法，对跨语言的百科信息框属性进行模板生成与跨语言链接的匹配，并将结果应用到跨语言知识图谱上。重点针对英文维基与百度百科两个百科的异构性提出属性对齐流程与框架，力争抽取更多信息框属性，并提高跨语言对齐的召回率与准确率。在之后构建的知识库上，使用属性对齐结果丰富知识链接。最后为观察知识可用性，实现知识应用，开发展示系统与实体链接接口，以支持数据访问。下文将给出本文工作的主要思想与方法描述。

\subsection{基于百科的跨语言属性对齐}
以往大部分解决跨语言属性对齐的研究都在维基百科上进行，维基百科丰富的知识储备、多语言的特性，有利于研究者探寻数据规律与特征。另一方面，虽然有语言差异，但在结构上，维基百科愈加完善的编辑规则使得不同语言的数据格式也大同小异，大大减小了对齐难度。

然而，维基百科中中英文知识相差悬殊，无论是词条还是信息框，数量都不对称。要想尽可能多的获得中文属性与跨语言关系，我们需要其他中文百科的辅助。

不同于大部分维基百科内部信息框属性对齐的研究，本文的工作焦点为在异构百科上寻找跨语言属性链接。除了中英文知识量不平衡现象，还面临异构特性所带来的百科规则的不同、人员编辑习惯的迥异等问题。我们对维基百科与百度百科的模板与属性的异同进行了详细的分析（详见\ref{sec:template-property-analysis}）

我们提出跨语言属性对齐框架（详见\ref{sec:property-matching}），这里，跨语言对齐被看作是一个二分类问题，为达到更精确的结果与更高的召回率，我们精炼属性抽取方法，抽取跨语言种子避免人工标准、添加同语言相似属性合并模块提高召回。

在属性抽取一步，百度百科的网页结构化信息较为容易处理，但维基百科信息框所依据的模板，定义却不统一。通过对维基百科模板的观察，我们为不同的模板定义提供了相应的抽取规则，将可能获得维基百科信息框模板与属性数量最大化（详见\ref{sec:property-extraction}）。

得益于维基百科的多语言特性，通过模板对齐、属性值匹配等方法，可预先获得一批精准度高的属性跨语言对齐关系。该集合可以作为构建跨语言本体的资源。但以中英文维基对齐属性为桥梁匹配的维基与百科属性，仅是凤毛麟角，因为百科异构性，还有大量的中英文跨百科属性有待进一步分析。这批跨语言对齐属性，将作为进一步抽取更多属性对齐关系的种子集合。这一步更避免了监督学习问题常见的训练集合的人工标注问题（详见\ref{sec:cross-lingual-seed}）。

属性是有歧义的，同样名称的属性，可能指代不同的意思，比如。。。属性的具体意义受限于领域，即名称为“”的属性，在xx领域中是yy的意思，而在领域xx中可以是yy的意思。我们通过生成领域模板来达到区分属性的目的。除此之外，模板代表着指定领域可能涉及的属性集合，是该领域主要特性的描述，在信息框编辑时也起着规范的作用，因此生成领域模板有很大意义。在此之后，属性的分析在模板范围之内，减小了搜索空间，可以使算法运行效率有所提高（详见\ref{sec:domain-template}）

相对于一词多义，属性也存在一义多词问题，即描述相同意义的属性，有不同的写法。比如出生地点有“出生地”，“出生地点”，“”等多种写法，这种现象多是由于编辑者个人写作习惯不同。找出同领域的这些同义词，可以增加知识库中的sameAs关系，同时有助于提高跨语言对齐的召回率。我们从文本相似度、语义相似度等方面出发，计算同领域的属性集合中的两两相似性，将相似性高的属性合并成同一个属性（详见\ref{sec:similar-property}）

经过以上几个模块的处理，一定程度上削减了百科异构性带来的阻碍。相对于一些拉丁语系属性的对齐研究，中文与英文在写法上大相径庭，因此不可单纯依赖文本相似度。本文将跨语言属性对齐看作二分类问题，除了使用文本特征，还提出几项假设，比如同一属性的使用流行度相似、同一属性的对象值指代同一个实体等，从结构纬度抽取跨语言对的特征，训练分类器（详见\ref{sec:cross-lingual-property-matching}）。

\subsection{大规模中英文知识库XLore的构建}
本文以解决中文知识匮乏现象、提供中英文链接知识为出发点，构建跨语言知识库XLore。基于当今知识库的构建思想，我们以维基百科、百度百科、互动百科为数据源，从异构结构中抽取实例、概念、属性构成知识库。如何确定必要元素，如何进行信息清理与保留，是我们在知识抽取过程中需要考虑的。与同语言知识库构建不同的是，跨语言链接是融合多语言知识库的根本要素，我们对三类元素的链接分别进行了扩展，丰富了跨语言关系。

数据整理后，我们将结构化数据转换成RDF三元组，构成符合LOD要求的标准知识库（详见\ref{cha:cross-lingual-knowledge-base}）。

\subsection{XLore系统与应用接口构建}

知识库效果如何？是否可用？为了能直观地观察数据，我们为XLore搭建网页展示系统。提供开放式的数据访问，包括点击访问、搜索框查询、SPAQL语句查询、关系可视化等。从应用的角度，还搭建了基于知识库的实体链接查询接口，供文本相关研究调用（详见\ref{cha:xlore-system-api}）。

\section{本章小结}
本章首先从知识图谱的应用角度介绍了其重要性，之后从构建流程，提及可能涉及的问题与相关技术。根据本文的工作，还列举了两个中文知识库与YAGO多语言知识库，其构建思想对本文跨语言知识库的构建有很大借鉴意义。

其次，指出属性对于实体描述的重要性，以及跨语言属性对构建跨语言知识库的意义。讨论当前信息框属性涉及到的研究点与相关技术，结合本文的数据情况进行思考。

再次，针对知识库的利用问题，着重介绍了知识链接有关技术。这部分为本文知识库实体链接接口的创建提供了指导。

最后，提出了本文工作的特色，并在以上相关研究的启发下，形成自己的问题解决思路，提出具体解决方案。

